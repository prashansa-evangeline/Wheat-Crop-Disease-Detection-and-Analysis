{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1CkzCFiGadzE3Otmsj_GHfZoKmGUd6po_","authorship_tag":"ABX9TyMcO1ZbJOmQW1Fc77l7O2zD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1W1mRING82pM"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.models import load_model\n","from sklearn.metrics import classification_report\n","from keras.applications import VGG19\n","from imutils import paths\n","from collections import deque\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import os\n","import pickle"]},{"cell_type":"code","source":["LABELS = set([\"Crown and Root Rot\", \"Healthy Wheat\", \"Leaf Rust\", \"Wheat Loose Smut\"])\n","dataset = '/content/drive/MyDrive/prashansa dataset - vgg19'\n","imagePaths = list(paths.list_images(dataset))\n","data = []\n","labels = []\n","# loop over the image paths\n","for imagePath in imagePaths:\n","  # extract the class label from the filename\n","  label = imagePath.split(os.path.sep)[-2]\n","  # if the label of the current image is not part of the labels\n","  # are interested in, then ignore the image\n","  if label not in LABELS:\n","    continue\n","  # load the image, convert it to RGB channel ordering, and resize\n","  # it to be a fixed 224x224 pixels, ignoring aspect ratio\n","  image = cv2.imread(imagePath)\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  image = cv2.resize(image, (224, 224))\n","  # update the data and labels lists, respectively\n","  data.append(image)\n","  labels.append(label)"],"metadata":{"id":"foEiyiJQ8-b_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert the data and labels to NumPy arrays\n","data = np.array(data)\n","labels = np.array(labels)\n","# perform one-hot encoding on the labels\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n","# partition the data into training and testing splits using 75% of\n","# the data for training and the remaining 25% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data, labels,\n"," test_size=0.25, stratify=labels, random_state=42)"],"metadata":{"id":"_-e0pn9e9Gr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","np.save('preprocessed_data.npy', data)  # Save"],"metadata":{"id":"NNv1faiFM-c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save('preprocessed_labels.npy', labels)"],"metadata":{"id":"nhDXyKRBNyJi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the training data augmentation object\n","trainAug = ImageDataGenerator(\n"," rotation_range=30,\n"," zoom_range=0.15,\n"," width_shift_range=0.2,\n"," height_shift_range=0.2,\n"," shear_range=0.15,\n"," horizontal_flip=True,\n"," fill_mode=\"nearest\")\n","# initialize the validation/testing data augmentation object (which\n","# we'll be adding mean subtraction to)\n","valAug = ImageDataGenerator()\n","# define the ImageNet mean subtraction (in RGB order) and set the\n","# the mean subtraction value for each of the data augmentation\n","# objects\n","mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n","trainAug.mean = mean\n","valAug.mean = mean"],"metadata":{"id":"rO7pp9Z49JwR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the VGG19 network, ensuring the head FC layer sets are left\n","# off\n","headmodel = VGG19(weights=\"imagenet\", include_top=False,\n","                  input_tensor=Input(shape=(224, 224, 3)))\n","# construct the head of the model that will be placed on top of the\n","# the base model\n","model = headmodel.output\n","model = AveragePooling2D(pool_size=(5, 5))(model)\n","model = Flatten(name=\"flatten\")(model)\n","model = Dense(512, activation=\"relu\")(model)\n","model = Dropout(0.4)(model)\n","model = Dense(len(lb.classes_), activation=\"softmax\")(model)\n","# place the head FC model on top of the base model (this will become\n","# the actual model we will train)\n","moodel = Model(inputs=headmodel.input, outputs=model)\n","# loop over all layers in the base model and freeze them so they will\n","# *not* be updated during the training process\n","for layer in headmodel.layers:\n","    layer.trainable = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8WiFlRt9MEb","executionInfo":{"status":"ok","timestamp":1714869132318,"user_tz":420,"elapsed":1927,"user":{"displayName":"Shanmukha Sri Harsha Anivilla","userId":"03174919478921368246"}},"outputId":"b39d1f47-266a-4d96-bf99-cf3388ea8a06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 0s 0us/step\n"]}]}]}